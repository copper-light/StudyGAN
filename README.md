### 1. Valina GAN
* Linear Layer 기반의 GAN
  * 배운 것
    * 랜덤 생성한 seed 값을 넣는데, 표준정규분포를 따르지 않고 완전 랜덤하게 넣으니까 학습이 되지 않음.
    * 레이어에 정규화 로직을 넣지 않으면 모드 붕괴가 일어남
    * 결국엔 위 두가지 모두 데이터가 특정 범위 내에 있다고 하더라도 데이터 정규화를 통해서 특정 기준을 중심으로 학습해야하는 것임

### 2. Conditional GAN
* Linear Layer 기반의 조건(생성할 클래스 지정) GAN

### 3. CNN GAN
* CNN 으로 만든 GAN
  * 배운 것
    * seed 값을 생성할때, 직접 2d 매트릭스에 해당하는 값을 생성했는데, linear하게 만들어내고 2d로 변환하는 것은 모델에게 학습하도록 하는것이 매우 결정적인 로직임
      * 모델에게 시드값의 임베딩을 직접 학습하도록 하는 것
    * 판별기와 생성기의 모델 수준은 유사해야함 -> 결국엔 판별기에서부터 흐르는 loss가 생성기의 품질을 결정하므로.
    * 생성기에서 전치Conv로 이미지 업샘플링할 때, 무조건 전치conv에 의지 하는 것보다 업샘플링은 필요할때 간결하게 하고 conv를 추가하여 이미지 품질을 높이는 방향으로 가는 것이 좋음 
    * 판별기에 dropout을 넣는 것과 안넣는 것은 하늘과 땅 차이임
    
* Conditional CNN GAN
  * 배운 것
    * 조건에 해당하는 label을 모델에게 넣을때 나름의 로직을 만들어서 2d onehot 으로 변환한 후에 생성 이미지와 합쳐서 2채널로 학습했는데, 이게 잘 안됐음
    * 이것도 원핫을 직접 2d 로 만들려고 하지 말고 이 또한 모델에게 원핫의 임베딩 값을 학습하도록 하는게 보다 나을 결과를 만들어냄
  